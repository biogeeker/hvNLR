RefIDs <- grep(pattern = "Athaliana", x=names(unmasked(maa)))
rowmask(maa) <- IRanges(start = RefIDs, end = RefIDs)
#Retrieving the non-masked subset------------------
RefAli <- as(maa, "AAStringSet")
RefLen <- width(RefAli[1])
## Calculating Consensus Matrix-----------------
(Tidy_CM<-as_tibble(t(consensusMatrix(RefAli, baseOnly = T))))
## Compensating for consensus matrix not keeping full alphabet in output
for (a in setdiff(Alph_21,colnames(Tidy_CM))){
vec <- as_tibble(0*(1:nrow(Tidy_CM)))
colnames(vec) <- paste(a)
Tidy_CM <- as_tibble(cbind(Tidy_CM,vec))
}
##Selecting relevant columns
(Tidy_CM_NoGaps <- select(Tidy_CM,Alph_20))
(Tidy_CM_Hydrophob <- select(Tidy_CM_NoGaps, Hydrophob))
##Entropy Calculation Ignoring Gaps-----------
entNG <- apply(Tidy_CM_NoGaps, 1, entropy,unit="log2") %>% as_tibble()
colnames(entNG)<-paste0("EntropyNoGaps_",gene)
entNG
## Hydrophobicity Claculation--------
Hphob <- apply(Tidy_CM_Hydrophob, 1, sum) %>% as_tibble()
Total <- apply(Tidy_CM_NoGaps, 1, sum) %>% as_tibble()
Hphob/Total %>% as_tibble() -> FracHphob
colnames(FracHphob)<-paste0("FrHphob_",gene)
head(FracHphob)
### Get all positions in sink using start coordinates of LRR---------
(annot <- LRR_Annotation %>% filter(Gene == gene & !is.na(RepNum)))
LRR_Entropy <-vector()
LRR_Hphob <- vector()
LRR_AA <-vector()
for (ii in 1:length(annot$Motiff))  {
line <- annot$Motiff[ii]
(values <- c(-4:13)+annot$Start[ii]-1)
(LRR_Entropy <- rbind(LRR_Entropy, c(gene,as.character(line),as.numeric(annot$Start[ii]),as.numeric(entNG[[1]][values]))))
(LRR_Hphob <- rbind(LRR_Hphob, c(gene,as.character(line),as.numeric(annot$Start[ii]),as.numeric(FracHphob[[1]][values]))))
(LRR_AA <- rbind(LRR_AA, c(gene,as.character(line),as.numeric(annot$Start[ii]),strsplit(as.character(RefSeqNG[[1]][values]),"")[[1]])))
}
All_LRR_Entropy[[j]] <- as_tibble(LRR_Entropy)
All_LRR_Hydrophob[[j]] <- as_tibble(LRR_Hphob)
All_LRR_AA[[j]] <- as_tibble(LRR_AA)
### Collect statistics on where the high entropy residues are
}
AAlist<-vector()
for(jj in seq_along(All_LRR_Hydrophob)){AAlist<-rbind(AAlist,All_LRR_AA[[jj]])}
colnames(AAlist) <- c("Gene","LRR","Start","Pm5","Pm4","Pm3","Pm2","Pm1","P1","P2","P3","P4","P5","P6","P7","P8","P9","P10","P11","P12","P13")
AAlist
Hphob<-vector()
for(jj in seq_along(All_LRR_Hydrophob)){Hphob<-rbind(Hphob,All_LRR_Hydrophob[[jj]])}
colnames(Hphob) <- c("Gene","LRR","Start","Pm5","Pm4","Pm3","Pm2","Pm1","P1","P2","P3","P4","P5","P6","P7","P8","P9","P10","P11","P12","P13")
Hphob
Entropy<-vector()
for(jj in seq_along(All_LRR_Entropy)){Entropy<-rbind(Entropy,All_LRR_Entropy[[jj]])}
colnames(Entropy) <- c("Gene","LRR","Start","Pm5","Pm4","Pm3","Pm2","Pm1","P1","P2","P3","P4","P5","P6","P7","P8","P9","P10","P11","P12","P13")
Entropy
library("tidyverse")
library("ggtree")
library("treeio")
library("tidytree")
'%ni%' <- Negate('%in%')
setwd("~/BioInf/Brachy/Protein/RAxML_237aa/")
########Import RAXML tree---------------
raxml <- read.raxml("./RAxML_bipartitionsBranchLabels.Raxml.out")
y <- as_tibble(raxml)
which(!is.na(y$label))
########Annotate Internal Nodes and save Bootstrap values---------------
z <- mutate(y, label=if_else(is.na(label),paste0("Int",node),label))
bs <- z %>% select(label,bootstrap)
########Import from iTol after rooting---------------
tree<-read.newick("YPO1up61DFSutQOmDIgGwg_newick.txt")
w <-as_tibble(tree)
x <- left_join(w,bs)
x
x %>% filter(label == "Int13000")
z %>% filter(label == "Int13000")
###Get number of leaves per node------
N_tips<-vector(length = nrow(x))
for (i in 1:nrow(x)){
nd <- x$node[[i]]
N_tips[[i]] <- length(offspring(x,nd, tiponly = T,self_include = T)$node)
}
x <- mutate(x, N_tips = N_tips)
x
## Find clades that are a good size and have best available support------
good_size_clades<-vector()
for (m in tree$tip.label){
#m <- messy[5,]$node
#m <- "7416_T436-R1/25-406"
print(m)
(ancestry <- ancestor(x,m) %>% filter(N_tips >40, N_tips <500))
n <- ancestry %>% filter(bootstrap == max(ancestry$bootstrap))
good_size_clades<-rbind(good_size_clades,n)
}
good_size_clades <- good_size_clades %>% distinct()
good_size_clades
good_size_clades %>% filter(bootstrap <95) %>% arrange(N_tips) %>% print(n=50)
##check that the assignment is unique
a <- good_size_clades$node
anc_pool<-vector()
offs_pool<-vector()
for (nd in a){
anc <- ancestor(x,nd)$node
anc_pool <- c(anc_pool,anc)
offs <- offspring(x,nd)$node
offs_pool <- c(offs_pool,offs)
}
anc_pool <- unique(anc_pool)
anc_pool
offs_pool <- unique(offs_pool)
offs_pool
partition <- good_size_clades
partition
partition <- x[a[which(a %ni% offs_pool)],]
partition <- good_size_clades
partition
(partition <- x[a[which(a %ni% offs_pool)],])
partition %>% select(N_tips) %>% sum()
x %>% filter(is.na(bootstrap))
partition %>% arrange(bootstrap) %>% print(n=300)
###Where are the missing tips and why are they missing?
tips<-tree$tip.label
missing<-vector()
for (a in 1:length(tips)){ if (x[a,]$node %ni% offs_pool){missing<-rbind(missing,x[a,])}}
missing
ancestor(x,4702)
compl<-vector()
for (n in missing$node){
(ancestry <- ancestor(x,n) %>% filter(N_tips <51))
c <- ancestry %>% filter(N_tips == max(ancestry$N_tips))
compl<-rbind(compl,c)
}
compl <- unique(compl)
compl
#compl <- missing
partition <-rbind(partition,compl)
##check that the assignment is unique
a <- partition$node
anc_pool<-vector()
offs_pool<-vector()
for (nd in a){
anc <- ancestor(x,nd)$node
anc_pool <- c(anc_pool,anc)
offs <- offspring(x,nd)$node
offs_pool <- c(offs_pool,offs)
}
anc_pool <- unique(anc_pool)
offs_pool <- unique(offs_pool)
partition
x[a[which(a %ni% offs_pool)],]
partition <- x[a[which(a %ni% offs_pool)],]
partition %>% select(N_tips) %>% sum()
length(tips)
partition %>% arrange(N_tips) %>% print(n=300)
ggplot(partition, aes(x=N_tips))+geom_histogram(binwidth = 1)
ggplot(partition, aes(x=N_tips))+geom_histogram(binwidth = 25)
ggplot(partition, aes(x=bootstrap))+geom_histogram(binwidth = 1)
#Loading libraries-----------------------------------------
library("tidyverse")
library("ggtree")
library("treeio")
library("msa")
library("entropy")
setwd("~/BioInf/Brachy/Protein/RAxML_237aa/Autoclades_70/")
MinGapFraction <- 0.9
MinGapBlockWidth <- 1
hvSiteEntCutoff <-  1.5
OutputDirectory <- "../Autoclades_70_Refinement_1/"
##Collect subdirectories and aligment files ending in *.best.fa
dirs <- dir(path = ".", pattern = "^Int*", recursive = F)
files <- list.files(path = dirs ,pattern = "*.best.fa$", recursive = F, full.names = TRUE) ### This now includes all subsequent subclades
##Calculate entropy with and without gap character, gather alignment stats---------------------
Alph_21 <- c("A","R","N","D","C","Q","E","G","H","I","L","K","M","F","P","S","T","W","Y","V","-")
Alph_20 <- c("A","R","N","D","C","Q","E","G","H","I","L","K","M","F","P","S","T","W","Y","V")
EntropyNG <- vector("list",length(files))
Entropy <- vector("list",length(files))
stats<-vector()
## Entropy calculation
for (i in seq_along(files)) {
## Read alignment
maa <- readAAMultipleAlignment(files[[i]])
## Extracting folder name
folder <- str_split(files[[i]], "/")[[1]][1]
## Filter out gappy columns
if ("-" %in% rownames(consensusMatrix(maa))){
autoMasked <- maskGaps(maa, min.fraction = MinGapFraction, min.block.width = MinGapBlockWidth) ##KEY FILTERING PARAMETERS
MinAli <- as(autoMasked, "AAStringSet")
}else{MinAli<-as(maa, "AAStringSet")}
MinAli
## Calculating Consensus Matrix
(Tidy_CM<-as_tibble(t(consensusMatrix(MinAli, baseOnly = T))))
## Compensating for consensus matrix not keeping full alphabet in output
for (a in setdiff(Alph_21,colnames(Tidy_CM))){
vec <- as_tibble(0*(1:nrow(Tidy_CM)))
colnames(vec) <- paste(a)
Tidy_CM <- as_tibble(cbind(Tidy_CM,vec))
}
##Selecting relevant columns
(Tidy_CM_Gaps <- select(Tidy_CM,all_of(Alph_21)))
(Tidy_CM_NoGaps <- select(Tidy_CM,all_of(Alph_20)))
##Entropy Calculation
ent <- apply(Tidy_CM_Gaps, 1, entropy,unit="log2") %>% as_tibble()
colnames(ent)<-paste0("Entropy_",folder)
ent
##Entropy Calculation Ignoring Gaps
entNG <- apply(Tidy_CM_NoGaps, 1, entropy,unit="log2") %>% as_tibble()
colnames(entNG)<-paste0("EntropyNoGaps_",folder)
entNG
##Save fraction of invariant positions with/without gaps and number of highly variable positions (without gaps)
frbl <- length(which(ent == 0))/nrow(ent)
frblng <- length(which(entNG == 0))/nrow(entNG)
nHVsites <- length(which(entNG > hvSiteEntCutoff))                          ####KEY CUTOFF PARAMETER
stats <- rbind(stats,c(folder,frbl,frblng,nrow(ent),nHVsites))
##Save results of entropy calculation
Entropy[[i]] <- ent
EntropyNG[[i]] <- entNG
}
EntropyNG
##Format stats tibble-------
colnames(stats)<-c("Clade","FractionZero","FractionZeroNG","Ali_Length","N_HV_Sites")
stats<-as_tibble(stats)
stats
stats<-mutate(stats, Clade = Clade,
FractionZero = as.numeric(FractionZero),
FractionZeroNG = as.numeric(FractionZeroNG),
N_HV_Sites = as.numeric(N_HV_Sites),
Ali_Length = as.numeric(Ali_Length)
)
stats %>% arrange(FractionZeroNG) %>% print(n=500)
# write_delim(stats, path = paste0(OutputDirectory,"/Stats.txt"), delim = "\t", col_names = T)
stats %>% filter(grepl("Int21623",Clade)) %>% arrange(FractionZeroNG)
##Plot distributions of invariant sites with/without gaps and of highly variable sites---------
ggplot(stats, aes(FractionZeroNG))+geom_histogram()
ggplot(stats, aes(N_HV_Sites))+geom_histogram()#+xlim(-1,50)
ggplot(stats, aes(x=FractionZeroNG, y=N_HV_Sites))+geom_point()+ylim(0,100)
ggplot(stats, aes(x=FractionZeroNG, y=FractionZero))+geom_point()+xlim(0,1)+ylim(0,1)
##Use cutoff value of 90% invariant sites (without gaps) for clades not to be split
DoNotSplit <- stats %>% filter(FractionZeroNG > 0.9) %>% arrange(Clade) %>% print(n=nrow(stats))
########################################
###Analyse clade trees------------------
###Import trees, calculate tree statistics, store all trees in BigTable object
'%ni%' <- Negate('%in%')
trees <- list.files(path = dirs,pattern = "RAxML_bipartitionsBranchLabels.*.First.out$", recursive = F, full.names = TRUE)
Annotation<-read_csv("../../NLR_Map.csv", col_names = c("Name","Assembly"))
(Annotation<-mutate(Annotation, label = toupper(Name)))
BigTable<-vector("list",length = length(trees))
for (i in seq_along(trees)){
#i <- 1
adress <- trees[[i]]
folder <- str_split(adress, "/")[[1]][1]
tree <- read.raxml(file = paste(adress))
(table <- as_tibble(tree))
(table<-mutate(table,Clade = folder))
(table <- left_join(table,Annotation, by = "label"))
###Get number of unique ecotypes left and right of every node
###Get number of duplicated ecotypes left and right of every node
x<-table
alltips<-tree@phylo$tip.label
CountTable<-vector()
for (nd in x$node){
#nd<-434
(R_tips <- offspring(x,nd, tiponly=T, self_include=T))
(L_tips <- x[which(alltips %ni% R_tips$label),])
nrow(L_tips)
if (nrow(L_tips) == 0){L_NE <- 0; L_ND <-0}else{
(L_ecotypes <- L_tips$Assembly)
L_NE <- length(unique(L_ecotypes))
L_ND <- length(unique(L_ecotypes[which(duplicated(L_ecotypes))]))
}
(R_ecotypes <- R_tips$Assembly)
R_NE <- length(unique(R_ecotypes))
R_ND <- length(unique(R_ecotypes[which(duplicated(R_ecotypes))]))
OE <- length(intersect(R_ecotypes,L_ecotypes))
vec <- c(nd,R_NE,R_ND,nrow(R_tips),L_NE,L_ND,nrow(L_tips),OE)
vec
CountTable <- rbind(CountTable, vec)
}
CountTable
###Merge with tree data
colnames(CountTable) <- c("node","R_Eco","R_DuplEco","R_tips","L_Eco","L_DuplEco","L_tips","N_OverlapEco")
x <- left_join(x,as_tibble(CountTable), by = "node")
###Add current tree with node statistics to the BigTable object
BigTable[[i]] <- x
}
## Flatten the list of tables into one table
Full_table<-vector()
for (i in seq_along(BigTable)){Full_table <- rbind(Full_table,BigTable[[i]])} ##This way runs faster than doing rbind within loop above
BigTable <- Full_table
## Check that the table is populated correctly
BigTable %>% filter(!is.na(label)) %>% select(label) %>% distinct() ###Number of genes in the clades under refinement
BigTable
ggplot(BigTable,aes(x=branch.length))+geom_histogram()+ylim(-1,201)
BigTable %>% filter(Name == "Bradi2g39247.1.p")
ggplot(BigTable, aes(x=branch.length))+geom_histogram()#+xlim(0.1,1)#+ylim(-1,100)
# ## Import Saved cut list:
Cut_Nodes_10<-read_delim("CutListSplit1_70.txt",delim = " ",col_names = T)
## Append a column to BigTable that contains the TRUE values for nodes in the cut list.
Cut_Nodes_10 <- mutate(Cut_Nodes_10, Split_Node_1 = T)
Cut_Nodes_10 <- Cut_Nodes_10 %>% filter(grepl("Int21623",Clade))
# ## Import Saved cut list:
Cut_Nodes_10<-read_delim("CutListSplit1_70.txt",delim = " ",col_names = T)
Cut_Nodes_10
## Append a column to BigTable that contains the TRUE values for nodes in the cut list.
Cut_Nodes_10 <- mutate(Cut_Nodes_10, Split_Node_1 = T)
#Cut_Nodes_10 <- Cut_Nodes_10 %>% filter(grepl("Int21623",Clade))
BigTable <- Full_table
BigTable <- left_join(BigTable, Cut_Nodes_10 %>% select(label,node,Clade,Split_Node_1)%>%distinct(), by = c("label","node","Clade"))
BigTable %>% filter(Split_Node_1)
Cut_Nodes_10 %>% filter(Split_Node_1)%>%select(Clade)
## Generate Split_1 column with new clade assignment for every tip of every tree
Split_1 <-vector(length = nrow(BigTable))
for (i in 1:nrow(BigTable)){if (!is.na(BigTable[i,]$label)){                    #works
(Tip <- BigTable[i,])
(CurClade <- BigTable[i,]$Clade)
(TreeData <- filter(BigTable,Clade == CurClade))
(SplitNodes <- filter(TreeData,Split_Node_1))
if (nrow(SplitNodes)>0){
(TopClade <- SplitNodes %>% filter(R_tips == max(SplitNodes$R_tips)))
if (is.na(Tip$Split_Node_1)){
if (nrow(dplyr::intersect(ancestor(TreeData,Tip$node),SplitNodes))>0){
SplitAncestors <- dplyr::intersect(ancestor(TreeData,Tip$node),SplitNodes)
SmallestAncestor <- SplitAncestors %>% filter(R_tips == min(SplitAncestors$R_tips))
BestNode <- paste0(CurClade,'_',SmallestAncestor$node,'_R')
}else{BestNode <- paste0(CurClade,'_',TopClade$node,'_L')}
}else{BestNode <- paste0(CurClade,'_',Tip$node,'_R')}
}else{BestNode <- paste0(CurClade,"_NS_N")}
Split_1[[i]] <- BestNode
}else{Split_1[[i]] <- NA}}
as_tibble(Split_1) %>% print(n=3000)
(BigTable_1 <- mutate(BigTable, Split_1 = as.factor(Split_1)))
#(BigTable_1 <- mutate(BigTable, Split_1 = as.factor(Split_1))%>%filter(grepl("Int21623_417_",Clade)))
BigTable_1 %>% print(n=1000)
## Count numbers of tips in each new clade
CladeStat <- BigTable_1 %>% filter(!is.na(Split_1)) %>% group_by(Clade,Split_1) %>% summarise(n=n()) %>% print(n=300)
CladeStat %>% ungroup() %>% select(Clade) %>% distinct()
CladeStat %>% ungroup() %>% select(Split_1) %>% distinct()
BigTable  %>% select(label) %>% distinct()
ggplot(CladeStat,aes(x=n))+geom_density()
ggplot(CladeStat,aes(x=n))+geom_density()+xlim(0,100)
ggplot(CladeStat,aes(x=n))+geom_histogram()
setwd("~/BioInf/Brachy/Protein/RAxML_237aa/Autoclades_70/")
library(tidyverse)
###IMPORT DATA#################
'%ni%' <- Negate('%in%')
(zeroth <-read_delim("../Autoclades_70/zerothassignment.txt",col_names = c("Clade_0","Gene"), delim = "\t"))
(first <-read_delim("../Autoclades_70_Refinement_1/firstassignment.txt",col_names = c("Clade_1","Gene"), delim = "\t"))
(second <-read_delim("../Autoclades_70_Refinement_2/secondassignment.txt",col_names = c("Clade_2","Gene"), delim = "\t"))
(third <-read_delim("../Autoclades_70_Refinement_3/thirdassignment.txt",col_names = c("Clade_3","Gene"), delim = "\t"))
(fourth <-read_delim("../Autoclades_70_Refinement_4/fourthassignment.txt",col_names = c("Clade_4","Gene"), delim = "\t"))
###JOIN DATA TOGETHER############
Common<-left_join(zeroth, first, by = "Gene")
Common<-left_join(Common,second,by = "Gene")
Common<-left_join(Common,third,by = "Gene")
Common<-left_join(Common,fourth,by = "Gene")
(Common<-unique(Common[c(2,1,3,4,5,6)])) ###Rearrange Columns
###FIND Multiple assignments for individual hits###########################
Common %>% select(Gene) %>% unique()
Common  %>% group_by(Gene) %>% filter(n()>1)  %>% summarise(N=n())%>% arrange(Gene) %>% print(n=300)
Common %>% group_by(Gene) %>% filter(n()>1)  %>% arrange(Gene) %>% print(n=300)
######MAKE a Column that uniquely establishes final assigned clade######
CladeA<-vector()
for (l in c(1:nrow(Common))){
b<-Common[l,]
a<-paste(b[2], sep ="")
if (!is.na(b[3])){a<-paste(b[3], sep ="")}
if (!is.na(b[4])){a<-paste(b[4], sep ="")}
if (!is.na(b[5])){a<-paste(b[5], sep ="")}
if (!is.na(b[6])){a<-paste(b[6], sep ="")}
CladeA<-append(CladeA, a, after = length(CladeA))
}
Common<-mutate(Common, Clade = CladeA)
Common
Common %>% select(Gene, Clade) %>% unique() %>% group_by(Gene) %>% filter(n()>1) %>% print(n=39) #Just one gene with non-unique assignment
Common %>% select(Gene, Clade) %>% unique()
####Find problem Clades#########
Common %>% select(Gene, Clade) %>% unique() %>% group_by(Gene) %>% filter(n()>1) %>% ungroup() %>% select(Clade) %>% unique()
#####Make a column that contains Ecotype ID only######
Annotation<-read_csv("../../NLR_Map.csv", col_names = c("Name","Assembly"))
(Annotation<-mutate(Annotation, Gene = toupper(Name)))
Common <- left_join(Common, Annotation, by = "Gene")
#####Find non-unique gene assignments#########
FixList <- Common %>% select(Gene,Clade) %>% distinct() %>% group_by(Gene) %>% filter(n()>1) %>% select(Gene) %>% distinct()
FixList
Common %>% filter(Gene %in% FixList$Gene) %>% arrange(Gene)
###FIND Singletons#########
SingletonClades <- Common %>% group_by(Clade) %>% summarise(n=n()) %>% filter(n<2) %>% select(Clade)
Common %>% filter(Gene %in% (Common %>% filter(Clade %in% SingletonClades$Clade))$Gene) %>% arrange(Gene) %>% group_by(Assembly) %>% summarise(n=n()) %>% print(n=100)
Common %>% filter(Gene %in% (Common %>% filter(Clade %in% SingletonClades$Clade))$Gene) %>% arrange(Gene) %>% group_by(Assembly) %>% summarise(n=n()) %>% select(n) %>% sum()
###CLADE Sizes####
Frequency_table <- Common %>% group_by(Clade) %>% summarise(n=n()) %>% arrange(n)
Frequency_table %>% print(n=500)
ggplot(Frequency_table, aes (x=n))+geom_density()+theme_classic()
ggplot(Frequency_table, aes (x=n))+geom_density()+theme_classic()+xlim(0,85)
ggplot(Frequency_table, aes (x=n))+geom_bar()+theme_classic()#+xlim(0,85)
Frequency_table
###Currently 409 clades based on the 11,479-tip tree
Common %>% select(Gene) %>% unique()
###Clade Characteristics###
AllClades<-levels(as.factor(Common$Clade))
Common$Clade
AllClades
AllEcotypes<-levels(Common$Assembly)
N_Ecotype<-vector()
NDupl_Ecotype<-vector()
for (l in AllClades){
#l <- "2_AT4G16920.1"
(a <- Common %>% filter(Clade == l) %>% select (Gene,Clade,Assembly) %>% distinct() %>% group_by(Assembly) %>% filter(n()>1) %>% distinct(Assembly) %>% nrow())
(b <- Common %>% filter(Clade == l) %>% select(Assembly) %>% distinct()%>% nrow())
N_Ecotype<-rbind(N_Ecotype, c(l,b))
NDupl_Ecotype<-rbind(NDupl_Ecotype, c(l,a))
}
N_Ecotype
colnames(N_Ecotype)<-c("Clade","N_Ecotype")
colnames(NDupl_Ecotype)<-c("Clade","NDupl_Ecotype")
(N_Ecotype<-as_tibble(N_Ecotype))
(NDupl_Ecotype<-as_tibble(NDupl_Ecotype))
EcoTibble<-left_join(N_Ecotype,NDupl_Ecotype,by = "Clade")
EcoTibble$N_Ecotype <- as.numeric(EcoTibble$N_Ecotype)
EcoTibble$NDupl_Ecotype <- as.numeric(EcoTibble$NDupl_Ecotype)
EcoTibble
pd <- position_dodge(width = 1)
EcoTibble
ggplot(EcoTibble %>% filter(N_HV_Sites<100), aes(x=N_Ecotype, y=NDupl_Ecotype,color = N_HV_Sites))+geom_point(position = pd)+ylim(-1,30)
EcoTibble %>% filter(NDupl_Ecotype >0) %>%arrange(N_Ecotype) %>% print(n=200)
#### Create a Pointer table to link individual genes to assemblies. Add column to Common.
dirs <- dir("..", pattern = "^Autoclades_70.*", full.names = T, recursive = F)
dirs2 <- dir(path=dirs, pattern = "Int.*",full.names = T)
files <- list.files(path = dirs2, pattern = "best.fa$",full.names = T)
files
clades <- unlist(strsplit(files, "/"))[4*1:length(files)-1]
Pointer <- tibble(Clade = clades, File = files)
Pointer
Common <- left_join(Common,Pointer, by = "Clade")
Common %>% filter(is.na(File))
### Now it is possible to create a list of genes with entropy strings
### with positions corresponding to the residues of the gene (i.e. remove gaps at the level of the gene)
### Can do this while cycling over Clades to save on reading
library(msa)
library(entropy)
hvSiteEntCutoff <- 1.5
MinGapFraction <- 1
MinGapBlockWidth <- 1
Alph_21 <- c("A","R","N","D","C","Q","E","G","H","I","L","K","M","F","P","S","T","W","Y","V","-")
Alph_20 <- c("A","R","N","D","C","Q","E","G","H","I","L","K","M","F","P","S","T","W","Y","V")
files<-levels(as.factor(Common$File))
EntropyNG <- vector("list",length(files))
Entropy <- vector("list",length(files))
stats<-vector()
## Entropy calculation
for (i in seq_along(files)) {
## Read alignment
maa <- readAAMultipleAlignment(files[[i]])
## Extracting folder name
str <- str_split(files[[i]], "/")[[1]]
folder <- str[[length(str)-1]]
print(paste("Looking at clade ",folder,"..."))
## Filter out gappy columns
if ("-" %in% rownames(consensusMatrix(maa))){
autoMasked <- maskGaps(maa, min.fraction = MinGapFraction, min.block.width = MinGapBlockWidth) ##KEY FILTERING PARAMETERS
MinAli <- as(autoMasked, "AAStringSet")
}else{MinAli<-as(maa, "AAStringSet")}
MinAli
## Calculating Consensus Matrix
(Tidy_CM<-as_tibble(t(consensusMatrix(MinAli, baseOnly = T))))
## Compensating for consensus matrix not keeping full alphabet in output
for (a in setdiff(Alph_21,colnames(Tidy_CM))){
vec <- as_tibble(0*(1:nrow(Tidy_CM)))
colnames(vec) <- paste(a)
Tidy_CM <- as_tibble(cbind(Tidy_CM,vec))
}
##Selecting relevant columns
(Tidy_CM_Gaps <- select(Tidy_CM,(Alph_21)))
(Tidy_CM_NoGaps <- select(Tidy_CM,(Alph_20)))
##Entropy Calculation
ent <- apply(Tidy_CM_Gaps, 1, entropy,unit="log2") %>% as_tibble()
colnames(ent)<-paste0("Entropy_",folder)
##Entropy Calculation Ignoring Gaps
entNG <- apply(Tidy_CM_NoGaps, 1, entropy,unit="log2") %>% as_tibble()
colnames(entNG)<-paste0("EntropyNoGaps_",folder)
##Save fraction of invariant positions with/without gaps and number of highly variable positions (without gaps)
frbl <- length(which(ent == 0))/nrow(ent)
frblng <- length(which(entNG == 0))/nrow(entNG)
nHVsites <- length(which(entNG > hvSiteEntCutoff))                          ####KEY CUTOFF PARAMETER
stats <- rbind(stats,c(folder,frbl,frblng,nrow(ent),nHVsites))
##Save results of entropy calculation
Entropy[[i]] <- ent
EntropyNG[[i]] <- entNG
}
##Format stats tibble-------
colnames(stats)<-c("Clade","FractionZero","FractionZeroNG","Ali_Length","N_HV_Sites")
stats<-as_tibble(stats)
stats
stats<-mutate(stats, Clade = Clade,
FractionZero = as.numeric(FractionZero),
FractionZeroNG = as.numeric(FractionZeroNG),
N_HV_Sites = as.numeric(N_HV_Sites),
Ali_Length = as.numeric(Ali_Length)
)
stats %>% arrange(-N_HV_Sites) %>% print(n=500)
N_Tips <- Common %>% group_by(Clade)%>%select(Gene)%>%summarise(N=n())
EcoTibble <- left_join(EcoTibble,N_Tips)
EcoTibble <- left_join(EcoTibble,stats)
HV_Clades <- stats %>% filter(N_HV_Sites>=10)
HV_Clades
Common %>% filter(Clade %in% HV_Clades$Clade)%>%group_by(Assembly)%>%summarise(n=n())%>% print(n=60)
Common %>% filter(Clade %in% HV_Clades$Clade, Assembly == "v2.1") %>% select(Gene,Clade) %>% unique() %>% print(n=200)
Common %>% filter(Clade %in% HV_Clades$Clade, Assembly == "v2.1") %>% group_by(Clade) %>% summarise(N=n()) %>% print(n=200)
levels(as.factor(Common$Assembly))
BradiHV <- Common %>% filter(Clade %in% HV_Clades$Clade, Assembly == "v2.1") %>% select(Gene) %>% mutate(Tr = str_remove(Gene,"...P$"))%>%select (Tr)%>%unique()%>%print(n=50)
# write_delim(BradiHV,"BradiHV.txt",col_names = F)
Common %>% select(Gene) %>% unique()
Common %>% select(Clade) %>% unique()
Common %>% filter(grepl("Bradi1g78926",Name)) %>% select(Clade_2)
